{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "F5C_Image_Caption_Bot_Genrative_Adversarial_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHG02gewCgxTZKnqWJOXe6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amansaini123/Final-Projects/blob/master/F5C_IMage_Caption_Bot_Genrative_Adversarial_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lynmAN1OXWcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Genrative deep learning involve creating models that can create new data\n",
        "# and one special type on model that we will build is known as GAN(genrative Adversarial Network)\n",
        "# Idea of GAN is proposed by Ian goodfellow in 2014\n",
        "# Most of the models we have build till now are Discriminative models(Predict Y from X) excpet the markov chain which is generative (Predict X from Y)\n",
        "# What discriminative model does is find the optimal hyper plane between classes and find the P(Y/X) based on that hyperplane\n",
        "# Here we will consider what is the probabilty of X given Y i.e P(X,Y)\n",
        "# Here our task would be say Generate a email which look like a spam\n",
        "# Neural Networks can be used in both i.e genrating a Discriminative and Generative Model\n",
        "# Till now we were calculating P(Y/X) and now here we are finding P(X/Y)\n",
        "\n",
        "\n",
        "\n",
        "# Till now we only know the difference between lion and elephant by seeing the features present to differnciate \n",
        "# But now we will build a lion and then match with both and say that this is a lion and other one is not\n",
        "# Both the models are doing the same job but the way of learning is different\n",
        "\n",
        "# The goal in genrative model P(X/Y) say X is marks and Y is physics and maths so here we will have all the physics and maths marks\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# This is our standard normal distribution with 0 mean and unit varience i.e u=0 and sigma=1\n",
        "# But say here in the case of physics we want mean =80 and sigma=10 so,X-u/sigma \n",
        "# Say maths st=20 and maths mean is 40\n",
        "# np.round for making everything as integer\n",
        "\n",
        "phy_std=5\n",
        "phy_mean=80\n",
        "phy=np.round(np.random.randn(500)*phy_std+phy_mean)\n",
        "math=np.round(np.random.randn(500)*10+40)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLMo7K9gk1Ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "92ac26fa-2734-4f8f-a5f4-7d2913a3b9d3"
      },
      "source": [
        "plt.hist(phy)\n",
        "plt.hist(math,alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOj0lEQVR4nO3dbYxmZX3H8e+vrIBg6vIw2eAudLZxg6GkFjNBGhpDWJOiEOEFoRjbbpFm05RWfCC62BekL0wgJaJNqsmGVbcJQQjSQKSxJSvE9gXbzoqRh3XrBkF2s7BjBLUaxa3/vrgPdbo7w8zcZ+65l2u+n2Qz51zn6Z+TM7+95jrnPneqCklSW35j3AVIkpaf4S5JDTLcJalBhrskNchwl6QGrRl3AQBnnnlmTU5OjrsMSXpd2bNnzw+qamKuZcdFuE9OTjI9PT3uMiTpdSXJc/Mtc1hGkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWjBcE/yhSSHkzw5q+3vknwnybeT/FOStbOW3Zxkf5J9Sf5wVIVLkua3mJ77l4DLjmp7GDi/qn4X+C/gZoAk5wHXAr/TbfO5JCcsW7WSpEVZMNyr6hvAD49q+9eqOtLNPgZs6KavBL5cVb+oqu8B+4ELl7FeSdIiLMcnVD8I3NNNr2cQ9q860LUdI8lWYCvAOeecswxlqCm3nzva/d+0b7T7l8as1w3VJH8DHAHuWuq2VbW9qqaqampiYs5XI0iShjR0zz3JnwFXAJvr19/VdxA4e9ZqG7o2SdIKGqrnnuQy4OPA+6rqZ7MWPQhcm+SkJBuBTcB/9C9TkrQUC/bck9wNXAKcmeQAcAuDp2NOAh5OAvBYVf1FVT2V5F7gaQbDNTdU1f+MqnhJ0twWDPeqev8czTteY/1PAZ/qU5QkzWdy20OLWu/ZWy8fcSXHNz+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWg5vqxDko47i30HDbT5Hhp77pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG+SEmDef2c8ddgaTXYM9dkhpkuEtSgwx3SWqQ4S5JDVow3JN8IcnhJE/Oajs9ycNJvtv9PK1rT5K/T7I/ybeTvGOUxUuS5raYnvuXgMuOatsG7KqqTcCubh7gPcCm7t9W4PPLU6YkaSkWDPeq+gbww6OarwR2dtM7gatmtf9jDTwGrE1y1nIVK0lanGHH3NdV1aFu+gVgXTe9Hnh+1noHurZjJNmaZDrJ9MzMzJBlSJLm0vuGalUVUENst72qpqpqamJiom8ZkqRZhg33F18dbul+Hu7aDwJnz1pvQ9cmSVpBw4b7g8CWbnoL8MCs9j/tnpq5CPjRrOEbSdIKWfDdMknuBi4BzkxyALgFuBW4N8n1wHPANd3q/wy8F9gP/Ay4bgQ1S2rQUr7QWgtbMNyr6v3zLNo8x7oF3NC3KElSP35CVZIa5Ct/W+ZreaVVy567JDXIcJekBhnuktQgx9y1Oo3yfsRN+0a3b2mR7LlLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBvcI9yUeSPJXkySR3Jzk5ycYku5PsT3JPkhOXq1hJ0uIMHe5J1gMfAqaq6nzgBOBa4Dbgjqp6K/AScP1yFCpJWry+wzJrgDcmWQOcAhwCLgXu65bvBK7qeQxJ0hINHe5VdRC4Hfg+g1D/EbAHeLmqjnSrHQDWz7V9kq1JppNMz8zMDFuGJGkOfYZlTgOuBDYCbwFOBS5b7PZVtb2qpqpqamJiYtgyJElz6DMs827ge1U1U1W/BO4HLgbWdsM0ABuAgz1rlCQtUZ9w/z5wUZJTkgTYDDwNPAJc3a2zBXigX4mSpKXqM+a+m8GN028CT3T72g58Avhokv3AGcCOZahTkrQEaxZeZX5VdQtwy1HNzwAX9tmvJKkfP6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ1a02fjJGuBO4HzgQI+COwD7gEmgWeBa6rqpV5VStIITW57aFHrPXvr5SOuZPn07bl/FvhaVb0NeDuwF9gG7KqqTcCubl6StIKGDvckbwbeBewAqKpXqupl4EpgZ7faTuCqvkVKkpamT899IzADfDHJ40nuTHIqsK6qDnXrvACsm2vjJFuTTCeZnpmZ6VGGJOlofcJ9DfAO4PNVdQHwU44agqmqYjAWf4yq2l5VU1U1NTEx0aMMSdLR+oT7AeBAVe3u5u9jEPYvJjkLoPt5uF+JkqSlGjrcq+oF4Pkk53ZNm4GngQeBLV3bFuCBXhVKkpas16OQwF8DdyU5EXgGuI7Bfxj3JrkeeA64pucxJElL1Cvcq+pbwNQcizb32a8kqR8/oSpJDeo7LCNJ81rsJz+1/Oy5S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGtQ73JOckOTxJF/t5jcm2Z1kf5J7kpzYv0xJ0lIsR8/9RmDvrPnbgDuq6q3AS8D1y3AMSdIS9Ar3JBuAy4E7u/kAlwL3davsBK7qcwxJ0tL17bl/Bvg48Ktu/gzg5ao60s0fANbPtWGSrUmmk0zPzMz0LEOSNNvQ4Z7kCuBwVe0ZZvuq2l5VU1U1NTExMWwZkqQ5rOmx7cXA+5K8FzgZ+E3gs8DaJGu63vsG4GD/MiVJSzF0z72qbq6qDVU1CVwLfL2qPgA8AlzdrbYFeKB3lZKkJRnFc+6fAD6aZD+DMfgdIziGJOk19BmW+T9V9SjwaDf9DHDhcuxXkjQcP6EqSQ0y3CWpQYa7JDXIcJekBi3LDVUN6fZzx12BpEbZc5ekBtlzl5bbqP8iu2nfaPevJthzl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoKHDPcnZSR5J8nSSp5Lc2LWfnuThJN/tfp62fOVKkhajT8/9CPCxqjoPuAi4Icl5wDZgV1VtAnZ185KkFTT0F2RX1SHgUDf9kyR7gfXAlcAl3Wo7gUeBT/SqUtJxZXLbQ+MuQQtYljH3JJPABcBuYF0X/AAvAOvm2WZrkukk0zMzM8tRhiSp0zvck7wJ+Arw4ar68exlVVVAzbVdVW2vqqmqmpqYmOhbhiRpll7hnuQNDIL9rqq6v2t+MclZ3fKzgMP9SpQkLVWfp2UC7AD2VtWnZy16ENjSTW8BHhi+PEnSMIa+oQpcDPwJ8ESSb3VtnwRuBe5Ncj3wHHBNvxIlSUvV52mZfwcyz+LNw+5XktSfn1CVpAYZ7pLUIMNdkhpkuEtSgwx3SWpQn0chJWlVWew7dZ699fIRV7Iwe+6S1CDDXZIa5LCMJC2zpbwSeVRDOPbcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoN8FFISsLTH93T8s+cuSQ0y3CWpQQ7LLOT2c8ddgfT/jeia3H3Sz3nnLz43kn1r5dlzl6QGGe6S1CDDXZIa9Pofc3dMXJKOYc9dkhpkuEtSg17/wzKSXtOLP/n5otfdfdJfjrASfNRyBY2s557ksiT7kuxPsm1Ux5EkHWsk4Z7kBOAfgPcA5wHvT3LeKI4lSTrWqHruFwL7q+qZqnoF+DJw5YiOJUk6yqjG3NcDz8+aPwC8c/YKSbYCW7vZ/06yb0S1vB6cCfxg3EUcZzwnx2rgnFyx3Dt83Z+T3NZr89+ab8HYbqhW1XZg+7iOfzxJMl1VU+Ou43jiOTmW5+RYnpP5jWpY5iBw9qz5DV2bJGkFjCrc/xPYlGRjkhOBa4EHR3QsSdJRRjIsU1VHkvwV8C/ACcAXquqpURyrEQ5PHctzcizPybE8J/NIVY27BknSMvP1A5LUIMNdkhpkuK+gJGcneSTJ00meSnJj1356koeTfLf7edq4a11pSU5I8niSr3bzG5Ps7l5fcU93Y35VSbI2yX1JvpNkb5LfX+3XSpKPdL87Tya5O8nJXitzM9xX1hHgY1V1HnARcEP3WoZtwK6q2gTs6uZXmxuBvbPmbwPuqKq3Ai8B14+lqvH6LPC1qnob8HYG52fVXitJ1gMfAqaq6nwGD2tci9fKnAz3FVRVh6rqm930Txj8sq5n8GqGnd1qO4GrxlPheCTZAFwO3NnNB7gUuK9bZTWekzcD7wJ2AFTVK1X1Mqv8WmHwhN8bk6wBTgEOscqvlfkY7mOSZBK4ANgNrKuqQ92iF4B1YyprXD4DfBz4VTd/BvByVR3p5g8w+E9wNdkIzABf7Iar7kxyKqv4Wqmqg8DtwPcZhPqPgD14rczJcB+DJG8CvgJ8uKp+PHtZDZ5NXTXPpya5AjhcVXvGXctxZg3wDuDzVXUB8FOOGoJZhdfKaQz+ctkIvAU4FbhsrEUdxwz3FZbkDQyC/a6qur9rfjHJWd3ys4DD46pvDC4G3pfkWQZvD72UwVjz2u5Pb1idr684AByoqt3d/H0Mwn41XyvvBr5XVTNV9UvgfgbXz2q/VuZkuK+gbix5B7C3qj49a9GDwJZuegvwwErXNi5VdXNVbaiqSQY3x75eVR8AHgGu7lZbVecEoKpeAJ5P8uo3wG8GnmYVXysMhmMuSnJK97v06jlZ1dfKfPyE6gpK8gfAvwFP8Ovx5U8yGHe/FzgHeA64pqp+OJYixyjJJcBNVXVFkt9m0JM/HXgc+OOq+sU461tpSX6PwU3mE4FngOsYdMhW7bWS5G+BP2Lw5NnjwJ8zGGNf1dfKXAx3SWqQwzKS1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXofwHKqHo2VA/qewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7w1ROAKoSpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now in Gan by seeing the graph we have to predict the function \n",
        "# this same can be done for images i.e pixel values can also be ploted on a graph\n",
        "\n",
        "\n",
        "\n",
        "# We will learn what values (Marks) the X can take if Y is a certain class\n",
        "\n",
        "\n",
        "# For genrating the GAN we use two neural network one is known as Genrator and other is Discriminator\n",
        "# Say theif is a generator that genrate fake currency but Police is a discriminator that knows the difference between fake and real currency\n",
        "# So police tell the theif that make the necessary changes in the fake cuureny to make it close to the real currency\n",
        "# This feedback goes via back propogation , so during this prosses both of these guys get trained\n",
        "# Hence we will have two neural network one is going to be genrator and other be discriminator\n",
        "\n",
        "\n",
        "\n",
        "# Generator take input as noise vector, Generate a image which is validated by discriminator\n",
        "# Discrimiator will throw a probabilty that image is real of fake\n",
        "\n",
        "\n",
        "# As the training continues both the genrator and discriminator become better by paying min, max game\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# We would be using stochastic gradient descent of our dataset \n",
        "# i.e sample mini batch of exams from noise prior and then sample mini batch from true data\n",
        "# And then use stochastic gradient descent or adam to update the weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_2AviG_fQbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47fdee9e-0cbb-4dba-8553-2422749419c1"
      },
      "source": [
        "# Tricks while Training the GAN\n",
        "# Instead of 0 and 1 use the inputs between -1 and 1 i.e use tanh as activation function\n",
        "# Noise vector to the generator initially should be sample in random normal districution i.e use randn funtion for this\n",
        "\n",
        "# We do not want that while backpropogation our value become zero , it can be a very small value but we dont want to be 0 \n",
        "# Hence instead of relu we use leak relu \n",
        "# Use adam as optimezer\n",
        "# Adam optimization is a stochastic gradient descent method that is based on adaptive estimation\n",
        "\n",
        "\n",
        "# In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function.\n",
        "\n",
        "# While in GD, you have to run through ALL the samples in your training set to do a single update \n",
        "# for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET \n",
        "# of training sample from your training set to do the update for a parameter in a particular iteration.\n",
        "#  If you use SUBSET, it is called Minibatch Stochastic gradient Descent.\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import *\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential,Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y78k6SZ9iZnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fd76bc6-b093-41f9-d40c-39e10b143d29"
      },
      "source": [
        "# We only need the training data\n",
        "\n",
        "(X_train,_),(_,_)=mnist.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz6-ukKti_Z4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b231bbdb-aa1a-4830-b8d0-b9f3a157398f"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N66Buv_UjIJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "01f522ee-b86d-47df-e773-06804e4d08b0"
      },
      "source": [
        "plt.imshow(X_train[0],cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzJ_9yA8jSQL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4ef5bdc5-e168-43ff-8c9b-ad38d51a6e6e"
      },
      "source": [
        "# Now we will normalize the data in the range of [-1 to 1]\n",
        "\n",
        "\n",
        "# Converting integer value to float and then subtracting the middle most value from it i.e we have all the pixels in the range of 0 to 255\n",
        "X_train=(X_train.astype('float32')-127.5)/127.5\n",
        "print(np.min(X_train))\n",
        "print(np.max(X_train))\n",
        "\n",
        "\n",
        "\n",
        "# We can see that maximum value is 1 and minimum value is -1 \n",
        "# Hence the data has been normalized"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhlH0B-ejxfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Adam optimization algorithm is an extension to stochastic gradient descent\n",
        "#  that has recently seen broader adoption for deep learning applications in computer vision and natural language processing.\n",
        "\n",
        "\n",
        "\n",
        "TOTAL_EPOCHS=50\n",
        "\n",
        "\n",
        "# How many images we are going to pass through discriminator in each batch\n",
        "BATCH_SIZE=256\n",
        "\n",
        "\n",
        "# In one epoch how much data will pass through discriminator ie no of images divided by batch size i.e number of mini batches\n",
        "NO_OF_BATCHES=int(X_train.shape[0]/BATCH_SIZE)\n",
        "\n",
        "\n",
        "# We would pick 128 fake samples and 128 real sample to the discriminator\n",
        "HALF_BATCH=128\n",
        "\n",
        "\n",
        "# Let say we have 100 dimensional noise which will be converted to 784 dimension vector which will for our 28*28 image\n",
        "NOISE_DIM=100\n",
        "\n",
        "\n",
        "# Learning rate(lr) , i.e we should use these as our defalut parameters\n",
        "# lr is basically the step_size of the algorithm \n",
        "# beta is the exponential decay of the algorithm\n",
        "adam=Adam(lr=2e-4,beta_1=0.5)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnihE3fzAA1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "60508bd1-1883-4426-d923-3bfec1addc04"
      },
      "source": [
        "# Now we should build our generator and discrimator part\n",
        "\n",
        "\n",
        "# Generator which inputs a noise which is 100 dimensional and outputs the vector which is 784 dimension\n",
        "# Its going to be a neural network\n",
        "\n",
        "\n",
        "# linear sequence of layers is the property of sequential model\n",
        "generator=Sequential()\n",
        "\n",
        "\n",
        "# Add 256 neurons to the first layer and input is 100 inputs\n",
        "generator.add(Dense(256,input_shape=(NOISE_DIM,)))\n",
        "\n",
        "# Now we will add the activation which is leaky relu\n",
        "# 0.2 is the value of alpha i.e when x is neagtive it will not give exact 0 it will give aplha*x\n",
        "generator.add(LeakyReLU(0.2))\n",
        "\n",
        "\n",
        "# Now we are adding another Dense layer that upscale from 256 to 512 dimensions and then another Leaky relu\n",
        "generator.add(Dense(512))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Repeating the Process and just doubling the neurons\n",
        "generator.add(Dense(1024))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "\n",
        "\n",
        "\n",
        "# We want final output to be 784 dimension with a activation of tanh Range of tanh is between -1 to 1\n",
        "generator.add(Dense(784,activation='tanh'))\n",
        "\n",
        "\n",
        "# Lets complie our model and loss will be our binary cross entropy as image can be real or fake we have only two options\n",
        "# If we are training a binary classifier chances are that we would be using binary cross entropy or log loss function\n",
        "\n",
        "generator.compile(loss='binary_crossentropy',optimizer='adam')\n",
        "\n",
        "\n",
        "generator.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 784)               803600    \n",
            "=================================================================\n",
            "Total params: 1,486,352\n",
            "Trainable params: 1,486,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S04GUS3PDqAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "91b0f79f-6441-4477-ed8b-edaf60684857"
      },
      "source": [
        "# We have used leaky relu as activation in all the middle layers and tanh as the activation in the last layer\n",
        "\n",
        "\n",
        "\n",
        "# Now lets us build the discriminator\n",
        "# Later on we will club both of these into one model\n",
        "discriminator=Sequential()\n",
        "\n",
        "# Input here is 784 dimension we squeze it to 512 dimension i.e we are doing down sampling i.e comverting Large vector to small\n",
        "discriminator.add(Dense(512,input_shape=(784,)))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "\n",
        "\n",
        "discriminator.add(Dense(256))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "\n",
        "# Here we have activation as sigmoid as binary classification i.e fake or not fake say\n",
        "discriminator.add(Dense(1,activation='sigmoid'))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer='adam')\n",
        "discriminator.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_PDzeUYHpOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can see we have 533,505 parameters in the discriminator\n",
        "\n",
        "# Now we will combine both generator and discriminator\n",
        "# When generator is working discriminator is paused and also vice versa\n",
        "# Hence firslty making discriminator as non trainable\n",
        "\n",
        "\n",
        "discriminator.trainable=False\n",
        "gan_input=Input(shape=(NOISE_DIM,))\n",
        "\n",
        "# Input is passed to the generator and that gives us the generated image \n",
        "generated_img=generator(gan_input)\n",
        "\n",
        "\n",
        "# and the generated_img is passed to the discriminator\n",
        "gan_output=discriminator(generated_img)\n",
        "\n",
        "\n",
        "\n",
        "model=Model(gan_input,gan_output)\n",
        "model.compile(loss='binary_crossentropy',optimizer=adam)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kI1WLyRLcI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "465152ed-27f8-4d0b-eee7-23a5b966a113"
      },
      "source": [
        "X_train=X_train.reshape(-1,784)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLwXD6SvJPNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "a229b103-743c-4911-9f2f-e77c2d76c811"
      },
      "source": [
        "# Training Loop\n",
        "# Now lets wirte the training loop \n",
        "# Training is not that simple we cannot write the fit function directly\n",
        "# As training is based on min max model\n",
        "\n",
        "\n",
        "d_losses = []\n",
        "g_losses = []\n",
        "\n",
        "\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    # For each epoch we have to calculate the genrator loss and the discrimator loss in the each epoch\n",
        "    # Firslty initialzing both of them as 0\n",
        "    epoch_d_loss = 0.\n",
        "    epoch_g_loss = 0.\n",
        "    \n",
        "    #Mini Batch SGD\n",
        "    for step in range(NO_OF_BATCHES):\n",
        "      # In each batch first step would be to train the discriminator\n",
        "      # And to train the discriminator we need 50 percent real data and 50 percent fake data\n",
        "\n",
        "      # So we are randomly taking half of the values from our data set \n",
        "      # randint take the low value i.e 0 , high value i.e X_train.shape and number of images i.e 128\n",
        "\n",
        "      # Real Data\n",
        "        \n",
        "        # Step-1 Discriminator \n",
        "        # 50% Real Data + 50% Fake Data\n",
        "        \n",
        "        # Real Data X\n",
        "        # numpy.random.randint(low, high=None, size=None, dtype=int)¶\n",
        "        #  So we are randomly taking half of the values from our data set \n",
        "        # randint take the low value i.e 0 , high value i.e X_train.shape and number of images i.e 128\n",
        "        idx = np.random.randint(0,X_train.shape[0],HALF_BATCH)\n",
        "        real_imgs = X_train[idx]\n",
        "        \n",
        "        #Fake Data X\n",
        "        # Number of images are equal to HALF_BATCH and shape would be equal to NOISE_DIM\n",
        "        noise = np.random.normal(0,1,size=(HALF_BATCH,NOISE_DIM))\n",
        "        fake_imgs = generator.predict(noise) #Forward \n",
        "        \n",
        "        \n",
        "        # Labels \n",
        "        real_y = np.ones((HALF_BATCH,1))*0.9 #One Side Label Smoothing for Discriminator\n",
        "        fake_y = np.zeros((HALF_BATCH,1))\n",
        "        \n",
        "        # Train our Discriminator\n",
        "        # We get the X values we get the y values now we have to train our discriminator\n",
        "        # According to the paper we will train on both the batches seprately \n",
        "        d_loss_real = discriminator.train_on_batch(real_imgs,real_y)\n",
        "        d_loss_fake = discriminator.train_on_batch(fake_imgs,fake_y)\n",
        "        d_loss = 0.5*d_loss_real + 0.5*d_loss_fake\n",
        "        \n",
        "        epoch_d_loss += d_loss\n",
        "        \n",
        "        # Train Generator (Considering Frozen Discriminator)\n",
        "        noise = np.random.normal(0,1,size=(BATCH_SIZE,NOISE_DIM))\n",
        "        ground_truth_y = np.ones((BATCH_SIZE,1))\n",
        "        g_loss = model.train_on_batch(noise,ground_truth_y)\n",
        "        epoch_g_loss += g_loss\n",
        "        \n",
        "    print(\"Epoch %d Disc Loss %.4f Generator Loss %.4f\" %((epoch+1),epoch_d_loss/NO_OF_BATCHES,epoch_g_loss/NO_OF_BATCHES))\n",
        "    d_losses.append(epoch_d_loss/NO_OF_BATCHES)\n",
        "    g_losses.append(epoch_g_loss/NO_OF_BATCHES)\n",
        "    \n",
        "    if (epoch+1)%5==0:\n",
        "        generator.save('model/gan_generator_{0}.h5'.format(epoch+1))\n",
        "        save_imgs(epoch)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Disc Loss 0.6819 Generator Loss 1.5885\n",
            "Epoch 2 Disc Loss 0.6648 Generator Loss 1.5903\n",
            "Epoch 3 Disc Loss 0.6228 Generator Loss 1.6468\n",
            "Epoch 4 Disc Loss 0.6564 Generator Loss 1.8389\n",
            "Epoch 5 Disc Loss 0.5574 Generator Loss 1.9064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7c6e99c79ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/gan_generator_{0}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0msave_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_write_to_gcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[0;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'model/gan_generator_5.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9nnd-rZTIM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "29d090ab-02d0-4ce0-be37-f41feac5101d"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for step in range(NO_OF_BATCHES):\n",
        "    # In each batch first step would be to train the discriminator\n",
        "    # And to train the discriminator we need 50 percent real data and 50 percent fake data\n",
        "\n",
        "    # So we are randomly taking half of the values from our data set \n",
        "    # randint take the low value i.e 0 , high value i.e X_train.shape and number of images i.e 128\n",
        "\n",
        "    # Real Data\n",
        "    idx=np.random.randint(0,X_train.shape[0],128)\n",
        "    real_imgs=X_train[idx]\n",
        "    \n",
        "\n",
        "    # Fake data\n",
        "    # Number of images are equal to HALF_BATCH and shape would be equal to NOISE_DIM\n",
        "    noise=np.random.normal(0,1,size=(HALF_BATCH,NOISE_DIM))\n",
        "\n",
        "    # We are not using the fit function instead we are using the predict function as it will also the forward pass\n",
        "    fake_imgs=generator.predict(noise)\n",
        "\n",
        "    \n",
        "    # What we have got so far is real data of X and fake data of X\n",
        "    # Now we also need the labels\n",
        "    # We have half_batch _size rows and 1 cols and every col is multiplied by 0.9\n",
        "    real_y=np.ones((HALF_BATCH,1))*0.9\n",
        "    fake_y=np.zeros((HALF_BATCH,1))\n",
        "\n",
        "\n",
        "\n",
        "    # We get the X values we get the y values now we have to train our discriminator\n",
        "    # According to the paper we will train on both the batches seprately \n",
        "\n",
        "    d_loss_real=discriminator.train_on_batch(real_imgs,real_y)\n",
        "    d_loss_fake=discriminator.train_on_batch(fake_imgs,fake_y)\n",
        "\n",
        "\n",
        "    # Giving equal weightage to both the loss\n",
        "    d_loss=0.5*d_loss_real+0.5*d_loss_fake\n",
        "\n",
        "    epoch_d_loss+=d_loss\n",
        "\n",
        "\n",
        "\n",
        "    # Train the generator considering forzen discriminator\n",
        "    noise=np.random.normal(0,1,size=(BATCH_SIZE,NOISE_DIM))\n",
        "\n",
        "    # We want all the y to be 1 i.e we want generator should always generate real images\n",
        "    ground_truth_y=np.ones((BATCH_SIZE,1))\n",
        "    g_loss=model.train_on_batch(noise,ground_truth_y)\n",
        "    epoch_g_loss+=g_loss\n",
        "  \n",
        "\n",
        "  # After every 5 epoch we are going to store our generator object\n",
        "  if(epoch+1)%5==0:\n",
        "    generator.save('model/gan_generator_{0}.h5'.format(epoch+1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generator genrates 128 images by taking 128 imput vectors and discrimitor take these 128 images along with 128 random images and find the loss\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-f19e1900c464>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    for step in range(NO_OF_BATCHES):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJeHjv3LMBke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}